{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba00e1ba",
   "metadata": {},
   "source": [
    "# Step05 - Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21748533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f2ae2",
   "metadata": {},
   "source": [
    "### read scoring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8454138",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'target'\n",
    "model = 'xgboost'\n",
    "pk_lst = ['id']\n",
    "\n",
    "oot_sdf = spark.read.parquet(path + 'data' + model + '.parquet')\n",
    "oot_sdf = oot_sdf.withColumnRenamed(target,'target')\n",
    "\n",
    "print(\"number of cols:\", len(oot_sdf.columns))\n",
    "oot_sdf.agg(F.sum(F.col('target')).alias('tot pos'),\n",
    "           F.count('*').alias('tot rows'),\n",
    "            (F.sum(F.col('target'))/F.count('*')).alias('target rate')).show()\n",
    "\n",
    "#convert to pandas for scoring\n",
    "oot = oot_sdf.toPandas()\n",
    "print(\"scoring data converted into pandas\")\n",
    "oot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb2399",
   "metadata": {},
   "source": [
    "### Load pre-requisite files (list of features, decile cutoffs, and optimal threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dadc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# A. list of model features\n",
    "# =============================\n",
    "filename = (path + model + 'feat_lst')\n",
    "lst = pickle.load(open(filename,'rb'))\n",
    "print(\"list of features loaded\")\n",
    "print(lst)\n",
    "\n",
    "# ===========================================\n",
    "# B. raw prob cutofds to assign deciles\n",
    "# ===========================================\n",
    "filename = (path + model + '_train_decile_cutoffs')\n",
    "lst = pickle.load(open(filename,'rb'))\n",
    "print(\"cutoffs loaded\")\n",
    "\n",
    "# ===========================================\n",
    "# C. optimal prob threshold for classification\n",
    "# ===========================================\n",
    "pr_thresh = 0.54212"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33150ed3",
   "metadata": {},
   "source": [
    "### Load models as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Load uncalibrated model \n",
    "# ===============================================\n",
    "print(\"loading uncalibrated model\")\n",
    "saved_clf = load_model(path = path, name = model)\n",
    "\n",
    "# ====================================\n",
    "# Load calibrated model\n",
    "# ====================================\n",
    "print(\"loading calibrated model\")\n",
    "saved_clf_cal = load_model(path = path, name = model + '_platt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf501bf",
   "metadata": {},
   "source": [
    "### dataframe for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468e009",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrn_data = pd.concat([pd.DataFrame(oot[pk]),\n",
    "                       pd.DataFrame(saved_clf.predict_proba(oot[lst].values)[:,1],columns=['praw']),\n",
    "                       pd.DataFrame(saved_clf_cal.predict(saved_clf.predict_proba(oot[lst].values)[:,1]),columns=['pcal']),\n",
    "                       pd.DataFrame(oot['target'],columns=['target'])],axis=1)\n",
    "\n",
    "#predicted class assignment based on optimal threshold\n",
    "scrn_data['pclass'] = np.where(scrn_data['praw'] > pr_thresh,1,0)\n",
    "print(\"out-time predictions complete\")\n",
    "scrn_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17ae378",
   "metadata": {},
   "source": [
    "### assign deciles based on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0339c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read scoring as spark dataset\n",
    "scrn_data = spark.read.parquet(path + 'scored_file.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b269c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "decile_map = {0:10,\n",
    "              1:9,\n",
    "              2:8,\n",
    "              3:7,\n",
    "              4:6,\n",
    "              5:5,\n",
    "              6:4,\n",
    "              7:3,\n",
    "              8:2,\n",
    "              9:1}\n",
    "\n",
    "#read spark dataframe using raw \"p1\"\n",
    "bucketizer = Bucketizer(splits = cutoffs, inputCol = 'praw', outoutCol = 'buckets')   #raw prob on imbalanced set\n",
    "scrn_data_n = bucketizer.setHandleInvalid('keep').transform(scrn_data)\n",
    "\n",
    "#map to training decile cutoffs\n",
    "pdf = scrn_data_n.toPandas()\n",
    "pdf['buckets'] = pdf['buckets'].map(decile_map)\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a278fc4",
   "metadata": {},
   "source": [
    "## ===================================\n",
    "## Stats \n",
    "## ==================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95482dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scrn_data_n.groupBy('buckets')\\\n",
    "                .agg(F.mean(F.col('target')).alias('actual'),\n",
    "                    F.sum(F.col('target')).alias('tot events'),\n",
    "                     F.mean(F.col('pcal')).alias('cal_prob'),\n",
    "                     F.min(F.col('pcal')).alias('min_cal_prob'),\n",
    "                     F.max(F.col('pcal')).alias('max_cal_prob'),\n",
    "                     F.count(F.lit(1)).alias('count'))\n",
    "pdf = df.toPandas()\n",
    "pdf = pdf.sort_values(by = 'buckets', ascending = False)\n",
    "pdf['buckets'] = pdf['buckets'].map(decile_map)\n",
    "pdf.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pclass\n",
    "df = scrn_data_n.groupBy(['buckets','pclass'])\\\n",
    "                .agg(F.mean(F.col('target')).alias('actual'),\n",
    "                    F.sum(F.col('target')).alias('tot events'),\n",
    "                     F.mean(F.col('pcal')).alias('cal_prob'),\n",
    "                     F.min(F.col('pcal')).alias('min_cal_prob'),\n",
    "                     F.max(F.col('pcal')).alias('max_cal_prob'),\n",
    "                     F.count(F.lit(1)).alias('count'))\n",
    "pdf = df.toPandas()\n",
    "pdf = pdf.sort_values(by = 'buckets', ascending = False)\n",
    "pdf['buckets'] = pdf['buckets'].map(decile_map)\n",
    "pdf.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf00859",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.pivot(index = 'buckets', columns = 'pclass', values = ['count'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
